##Function to Calculate P(B)
calculate_probability = function(x, feature, params_table) {
#x: [numeric] the relative abundance of the feature of interest
#feature: [string] feature of interest with representation in the provided parameter table
#pararms_table: [parameter x feature data.frame/matrix] parameter table containing P(not detected) and shape parameters for beta distribution.
if(x == 0) {
#Get P(not detected)
return(params_table["pNotDetected",feature])
}  else {
#Prob detected from beta div
return(c(1- params_table["pNotDetected",feature])*dbeta(x = x, shape1 = params_table["shape1",feature], shape2 = params_table["shape2",feature]))
}
}
prior = function(alpha, mu, sig) {
# Gaussian distribution
res = (mu-alpha)/sig^2
return(res)
}
getMapEstimates = function(taxa) {
# maximum a posteriori estimation
# require(matlib)
taxa = taxa[taxa>0]
n = length(taxa)
if (n == 0) {return(c(1,1))}
#Constants
weight = 10 #supplies weakness coefficient to the varaince of the normal distributions
mu_a = 1
sig_a = 0.3*weight
mu_b = 1
sig_b = 10*weight
i = 0
alpha_old = runif(1, min = 0, max = 2)
beta_old = runif(1, min = 0, max = 100)
while(TRUE) {
if (i>1000) {break}
g_1 = digamma(alpha_old+beta_old) - digamma(alpha_old) + mean(log(taxa)) + prior(alpha_old, mu = mu_a, sig = sig_a)/n
g_2 = digamma(beta_old+alpha_old) - digamma(beta_old) + mean(log(1-taxa)) + prior(beta_old, mu = mu_b, sig = sig_b)/n
#hessian functions
g_11 = trigamma(alpha_old+beta_old) - trigamma(alpha_old) - 1/sig_a^2/n
g_12 = trigamma(alpha_old+beta_old)
g_21 = trigamma(alpha_old+beta_old)
g_22 = trigamma(alpha_old+beta_old) - trigamma(beta_old) - 1/sig_b^2/n
#Solve
matrix_a =  matrix(data = c(g_11, g_21, g_12, g_22), 2, 2)
#Ensure Solution is Not Singular
matrix_a = try(solve(matrix_a), silent = TRUE)
if (class(matrix_a) == "try-error") {
alpha_old = runif(1, min = 0, max = 2)
beta_old = runif(1, min = 0, max = 100)
i = i+1
next
}
vector_b = c(g_1, g_2)
results = c(alpha_old, beta_old) - matrix_a%*%c(g_1, g_2)
alpha_new = results[1]
beta_new = results[2]
if (alpha_new<0 | beta_new<0) {
alpha_old = runif(1, min = 0, max = 2)
beta_old = runif(1, min = 0, max = 100)
i = i+1
next
}
convergence = all(abs(results - c(alpha_old, beta_old))/results<0.001)
if (convergence) {
output = c(alpha_new, beta_new)
names(output) = c("shape1", "shape2")
return(output)
} else {
alpha_old = alpha_new
beta_old = beta_new
i = i+1
next
}
}
return(c("Failure", alpha_new, beta_new, alpha_old, beta_old))
}
#General Acquire Parameters Function
acquire_parameters = function(asv_table) {
pNotDetected = apply(X = asv_table, MARGIN = 1, estimate_binomial_parameter)
betaParams = apply(X = asv_table, MARGIN = 1, getMapEstimates)
savedParams = rbind(pNotDetected, betaParams)
row.names(savedParams) = c("pNotDetected", "shape1", "shape2")
return(savedParams)
}
#General Calculate P(X|Y) function)
p_giv_class = function(features, asv_table, param_table, sample_data) {
p_given_class = matrix(nrow = length(features), ncol = dim(as.matrix(asv_table))[2])
if (dim(as.matrix(asv_table))[2]>1){
colnames(p_given_class) = colnames(asv_table)
} else {
colnames(p_given_class) = sample_data[1]
}
rownames(p_given_class) = features
for (feature in features)  {
if (length(sample_data) > 2) {
for(sample in colnames(asv_table)) {
p_given_class[feature,sample] = calculate_probability(x = asv_table[feature,sample],
feature = feature,
params_table = param_table)
}
} else {
p_given_class[feature,sample_data[1]] = calculate_probability(x = asv_table[feature],
feature = feature,
params_table = param_table)
}
}
return(p_given_class)
}
make_confusion_matrix = function(p1v2) {
require(caret)
final = as.factor(p1v2["result",])
truth = as.factor(p1v2["truth",])
output = confusionMatrix(final, truth)
}
get_modeled_features = function(model) {
modeled_features = colnames(model[[1]])
return(modeled_features)
}
# NBC Training Function
train_NBC = function(asv_table, sample_data, minimum_detection, min_rel_abund) {
# "asv_table" = double
#         rows= ASV names, cols=sample names
# "sample_data" = character matrix
#         column 1 = sample names; column 2 = class labels (e.g. "asthmatic" and "healthy")
# "minimum_detection" = integer
#         is how many samples in which the ASV has to be present in to be included in the training
# "min_rel_abund" = integer
#         sequencing detection limit - the relative abundance value at which we no longer trust the ASV is truly present
require(EnvStats)
#filter asv_table
asv_table = asv_table[,sample_data[,1]]
# print(dim(asv_table))
asv_table = asv_table[rowSums(asv_table>min_rel_abund)>=minimum_detection,]
#acquire class names
sample_classes = sort(unique(sample_data[,2])) # class 1 is always alphabetically first
#acquire overall parameters
savedParams_overall = acquire_parameters(asv_table = asv_table)
#acquire parameters for class 1
sample_data_1 = sample_data[sample_data[,2]==sample_classes[1],]
asv_table_1 = asv_table[,sample_data_1[,1]]
# asv_table_1 = asv_table_1[rowSums(asv_table_1>0)>=minimum_detection,] # getting rid of this for md=7
savedParams_class1 = acquire_parameters(asv_table = asv_table_1)
#acquire parameters for class 2
sample_data_2 = sample_data[sample_data[,2]==sample_classes[2],]
asv_table_2 = asv_table[,sample_data_2[,1]]
# asv_table_2 = asv_table_2[rowSums(asv_table_2>0)>=minimum_detection,] # getting rid of this for md=7
savedParams_class2 = acquire_parameters(asv_table = asv_table_2)
#Identify shared parameters
class_1_features = colnames(savedParams_class1)
class_2_features = colnames(savedParams_class2)
overall_features = colnames(savedParams_overall)
subset_features = intersect(class_1_features, class_2_features)
#Filter down to shared parameters
savedParams_overall = savedParams_overall[,subset_features]
savedParams_class1 = savedParams_class1[,subset_features]
savedParams_class2 = savedParams_class2[,subset_features]
prob_class1 = sum(sample_data[,2]==sample_classes[1])/nrow(sample_data)
model = list(savedParams_class1, savedParams_class2, savedParams_overall, sample_classes, prob_class1)
return(model)
}
perform_NBC = function(model, asv_table, sample_data, prob_class1) {
# "model" = object
#         direct output from train_NBC
# "asv_table" = double
#         rows= ASV names, cols=sample names
# "sample_data" = character matrix
#         column 1 = sample names; column 2 = class labels (e.g. "asthmatic" and "healthy")
# "prob_class1" = integer
#         number samples of test class 1 (class 1 is alphabetically first, class 2 is next) / total number samples
#         see "sample_classes" from train_NBC to check order
savedParams_overall = model[[3]]
savedParams_class1 = model[[1]]
savedParams_class2 = model[[2]]
subset_features = intersect(colnames(savedParams_overall), row.names(asv_table))
#filter asv_table
if(is.matrix(sample_data)){
asv_table = asv_table[subset_features, sample_data[,1]]
} else {
asv_table = asv_table[subset_features, sample_data[1]]}
#acquire class names
sample_classes = model[[4]]
##Calculate P(X|Y = class1)
p_given_class1 = p_giv_class(features = subset_features, asv_table = asv_table, param_table = savedParams_class1, sample_data = sample_data) # matrix cols=samples, rows=ASVs 90x95
p_given_class2 = p_giv_class(features = subset_features, asv_table = asv_table, param_table = savedParams_class2, sample_data = sample_data) # matrix cols=samples, rows=ASVs 90x95
p_x_independent_of_y = p_giv_class(features = subset_features, asv_table = asv_table, param_table = savedParams_overall, sample_data = sample_data) # matrix cols=samples, rows=ASVs 90x95
##Take the log of probabilities
p_given_class1 = log(p_given_class1)
p_given_class2 = log(p_given_class2)
p_x_independent_of_y = log(p_x_independent_of_y)
##Perform log(P(X|Y)) - log(P(X))
p_given_class1 = p_given_class1 - p_x_independent_of_y    # = log( P(class1 | X )
p_given_class2 = p_given_class2 - p_x_independent_of_y    # = log( P(class2 | X )
##Get ASV asthma scores = log( P(class1 | X ) - log( P(class2 | X )
#NOTE: class 1 is assumed as the case, class 2 is assumed as the control (we can make this user defined)
feature_scores = p_given_class1 - p_given_class2
##Sum log probabilities for each sample to acquire log(P(Y|X)) - log(P(Y))
p_1v2 = matrix(nrow = 4, ncol = dim(as.matrix(asv_table))[2])
if(is.matrix(sample_data)){
colnames(p_1v2) = colnames(asv_table)
} else {
colnames(p_1v2) = sample_data[1]
}
rownames(p_1v2) = c(sample_classes[1], sample_classes[2], "result", "truth")
p_1v2[sample_classes[1],] = colSums(p_given_class1)
p_1v2[sample_classes[2],] = colSums(p_given_class2)
##Finally, I just need to add the log(P(Y)) to each value in this table
prob_class2 = 1 - prob_class1
prob_class1 = log(prob_class1)
prob_class2 = log(prob_class2)
p_1v2[sample_classes[1],] = p_1v2[sample_classes[1],]+prob_class1
p_1v2[sample_classes[2],] = p_1v2[sample_classes[2],]+prob_class2
##Solve argmax.
p_1v2 = data.frame(p_1v2)
if(is.matrix(sample_data)){
p_1v2["truth",] = sample_data[,2]
} else {
p_1v2["truth",] = sample_data[2]
}
if(is.matrix(sample_data)){
for(p in sample_data[,1]) {
q = as.numeric(p_1v2[sample_classes, p])
p_1v2["result",p] = sample_classes[which(q == max(q))]
}
} else {
for(p in sample_data[1]) {
q = as.numeric(p_1v2[sample_classes, p])
p_1v2["result",p] = sample_classes[which(q == max(q))]
}
}
classification_rate = sum(p_1v2["result",]==p_1v2["truth",])/ncol(p_1v2)
output = list(classification_rate = as.numeric(classification_rate),
sample_by_sample = p_1v2,
model = model,
score_per_feature_per_sample = feature_scores)
return(output)
}
# Histograms of sample scores (makes 3 plots)
make_sample_score_histograms <- function(scores.df,
donor0 = "MARS0022.F.16s", donor1 = "MARS0043.F.16s",
class1.color = "#DE4968FF", class0.color = "#51127CFF", both.color = "lightblue",
class.to.plot,  # 0, 1, 2 (BOTH)
x.label = "Sample Score")
{
hist(scores.df$score, main="ALL Sample Scores", xlab = x.label, col = "lightblue", breaks=10)
abline(v = scores.df[donor1,]$score, col = class1.color, lwd = 2, lty="dashed")
abline(v = scores.df[donor0,]$score, col = class0.color, lwd=2, lty="dashed")
hist(scores.df$score[scores.df$class == 1],
main="Asthmatic (36) Sample Scores", xlab = x.label,
breaks =15, col = class1.color)
abline(v = scores.df[donor1,]$score, col = "black", lwd = 2, lty="dashed")
median(scores.df$score[scores.df$class == 1])
hist(scores.df$score[scores.df$class == 0],
main="Healthy (59) Sample Scores", xlab = x.label,
breaks = 20, col = class0.color)
abline(v = scores.df[donor0,]$score, col = "black", lwd=2, lty="dashed")
}
savedOutputs = list()
savedTests = list()
savedModels  = list()
scores = list()
sample_names_ordered = list()
pred <- matrix(nrow = num_samples)
pred_class <- matrix(nrow = num_samples)
true_class <- matrix(nrow = num_samples)
row.names(pred) <- my_sample_data[,1]
successes=0
#### TESTING RAREFACTION: ####
# count_asv_table = count_asv_table[!c(row.names(count_asv_table) %in% excludedTaxa),]
# count_asv_table = count_asv_table[,my_sample_data[,1]]  # 7867   95
#
# tmp_asv_table <- apply(X = count_asv_table,
#                         MARGIN = 2,
#                         FUN = rarefaction_subsample,
#                         sample.size = 1000,
#                         replace = FALSE)
# row.names(tmp_asv_table) = row.names(count_asv_table)
# my_asv_table = apply(X = tmp_asv_table, MARGIN = 2, FUN = function(x){x/sum(x)})
# my_asv_table = my_asv_table[rowSums(my_asv_table)>my_min_rel_abund,]  # 2125   95
#####
# scores_by_feature <- matrix(nrow = 88, ncol=num_samples)
for (i in 1:num_samples) {
print(i)
savedModels[[i]] = train_NBC(asv_table = my_asv_table,
sample_data = my_sample_data[-i,],
# training data is everything but the test sample
minimum_detection = my_minimum_detection,
min_rel_abund = my_min_rel_abund)
savedTests[[i]] = perform_NBC(model = savedModels[[i]],
asv_table = my_asv_table,
sample_data = my_sample_data[i,],
prob_class1 = probAsthma)
pred[i,1] <- ifelse(savedTests[[i]]$classification_rate == 1, TRUE, FALSE)
pred_class[i,1] <- as.character(data.frame(t(savedTests[[i]]$sample_by_sample))$result)
true_class[i,1] <- my_sample_data[i,2]
savedTests[[1]]$sample_by_sample["result",]
print(ifelse(savedTests[[i]]$classification_rate == 1, TRUE, FALSE))
successes = successes+savedTests[[i]]$classification_rate
ithscore = as.numeric(savedTests[[i]]$sample_by_sample["asthmatic",])-as.numeric(savedTests[[i]]$sample_by_sample["healthy",])
scores = c(scores, ithscore)
# print(ithscore)
ithsample = my_sample_data[i,][1]
sample_names_ordered = c(sample_names_ordered, ithsample)
}
savedOutputs = list()
savedTests = list()
savedModels  = list()
scores = list()
sample_names_ordered = list()
pred <- matrix(nrow = num_samples)
pred_class <- matrix(nrow = num_samples)
true_class <- matrix(nrow = num_samples)
row.names(pred) <- my_sample_data[,1]
successes=0
#### TESTING RAREFACTION: ####
# count_asv_table = count_asv_table[!c(row.names(count_asv_table) %in% excludedTaxa),]
# count_asv_table = count_asv_table[,my_sample_data[,1]]  # 7867   95
#
# tmp_asv_table <- apply(X = count_asv_table,
#                         MARGIN = 2,
#                         FUN = rarefaction_subsample,
#                         sample.size = 1000,
#                         replace = FALSE)
# row.names(tmp_asv_table) = row.names(count_asv_table)
# my_asv_table = apply(X = tmp_asv_table, MARGIN = 2, FUN = function(x){x/sum(x)})
# my_asv_table = my_asv_table[rowSums(my_asv_table)>my_min_rel_abund,]  # 2125   95
#####
# scores_by_feature <- matrix(nrow = 88, ncol=num_samples)
for (i in 1:num_samples) {
print(i)
savedModels[[i]] = train_NBC(asv_table = my_asv_table,
sample_data = my_sample_data[-i,],
# training data is everything but the test sample
minimum_detection = my_minimum_detection,
min_rel_abund = my_min_rel_abund)
savedTests[[i]] = perform_NBC(model = savedModels[[i]],
asv_table = my_asv_table,
sample_data = my_sample_data[i,],
prob_class1 = probAsthma)
pred[i,1] <- ifelse(savedTests[[i]]$classification_rate == 1, TRUE, FALSE)
pred_class[i,1] <- as.character(data.frame(t(savedTests[[i]]$sample_by_sample))$result)
true_class[i,1] <- my_sample_data[i,2]
savedTests[[1]]$sample_by_sample["result",]
print(ifelse(savedTests[[i]]$classification_rate == 1, TRUE, FALSE))
successes = successes+savedTests[[i]]$classification_rate
ithscore = as.numeric(savedTests[[i]]$sample_by_sample["asthmatic",])-as.numeric(savedTests[[i]]$sample_by_sample["healthy",])
scores = c(scores, ithscore)
# print(ithscore)
ithsample = my_sample_data[i,][1]
sample_names_ordered = c(sample_names_ordered, ithsample)
}
beep("mario")
pred_out <- cbind(sample_names_ordered, pred, pred_class, true_class, scores)
colnames(pred_out) <- c("samplename", "success", "pred", "truth", "score")
pred_out
pred_out_tmp
outdirectory = "~/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/nariel_evaluation/"
pred_out_nariel = readRDS(file = paste0(outdirectory, ASVTABLE, "_MAP_md", my_minimum_detection, "_RAmd", my_min_rel_abund, "/LOOCV_predictions.rds"))
pred_out_nariel == pred_out
pred_out
pred_out_narie
pred_out_nariel
pred_out$succ
pred_out = data.frame(pred_out)
predIntNormSimultaneousTestPower()
pred_out$cuss
pred_out$success
pred_out$success == data.frame(pred_out_tmp)$success
data.frame(pred_out_tmp)
pred_out$success == data.frame(pred_out_nariel)$success
pred_out_naria
pred_out_nariel
typeof(pred_out_nariel)
data.frame(pred_out_nariel)
pred_out_nariel = data.frame(pred_out_nariel)
pred_out_nariel$success == pred_out$success
cbind(pred_out_nariel[, c("samplename", "success", "score")], pred_out[, c("samplename", "success", "score")])
# Classification Rates
sum(pred) == successes # must be true
# Classification Rates
sum(pred) == successes # must be true
# Asthma Success Rate:
print("Asthma Success Rate:")
sum(cbind(data.frame(unlist(pred)), my_sample_data[,2])[,1][cbind(data.frame(unlist(pred)), my_sample_data[,2])[,2]=="asthmatic"])/sum(my_sample_data[,2] == "asthmatic")
# Healthy Success Rate:
print("Healthy Success Rate:")
sum(cbind(data.frame(unlist(pred)), my_sample_data[,2])[,1][cbind(data.frame(unlist(pred)), my_sample_data[,2])[,2]=="healthy"])/sum(my_sample_data[,2] == "healthy")
# LOOCV classification rate:
print("LOOCV Classification Rate")
print(sum(pred)/length(pred))
# Get sample scores to compare to non-CV full model
scores_by_sample_LOOCV_df <- data.frame(as.matrix(unlist(scores)))
rownames(scores_by_sample_LOOCV_df) <- sample_names_ordered
names(scores_by_sample_LOOCV_df) <- "scores_by_sample"
scores_by_sample_LOOCV_df$asthma <- my_sample_data[,2][my_sample_data[,1]==row.names(scores_by_sample_LOOCV_df)]
scores_by_sample_LOOCV_df$asthma <- factor(scores_by_sample_LOOCV_df$asthma)
scores_by_sample_plot <-
ggplot(data = scores_by_sample_LOOCV_df,
mapping = aes(x = seq(1, dim(scores_by_sample_LOOCV_df)[1]),
y = scores_by_sample_LOOCV_df$scores_by_sample[order(scores_by_sample_LOOCV_df$scores_by_sample)],
color = asthma))+
geom_point()+
labs(title="Score (diff of log probs) \n for each sample",
x="Ranked Sample", y = "log(Pr(A|x))-log(Pr(H|x))")+
theme_classic()
scores_by_sample_plot
# get median number of ASVs used:
# featurestot <- c()
# for (i in 1:num_samples) {
#   # featurestot[1,i] <- length(savedTests[[i]]$score_per_feature_per_sample)
#   featurestot <- c(featurestot, length(savedTests[[i]]$score_per_feature_per_sample))
#   }
# median(featurestot) # 462 for min detection of 2
# Confusion Matrix
library(yardstick)
predicted_class_names = pred_class
true_class_names = ifelse(scores_by_sample_LOOCV_df$asthma == "asthmatic", "asthmatic", "healthy")
true_class_binary = ifelse(scores_by_sample_LOOCV_df$asthma == "asthmatic", 1, 0)
truth_predicted <- data.frame(true_class_binary, predicted_class_names, true_class_names)
truth_predicted$true_class_binary <- as.factor(truth_predicted$true_class_binary)
# truth_predicted$predicted_class <- as.factor(truth_predicted$predicted_class)
truth_predicted$predicted_class_names <- as.factor(truth_predicted$predicted_class_names)
truth_predicted$true_class_names <- as.factor(truth_predicted$true_class_names)
cm <- conf_mat(truth_predicted, true_class_names, predicted_class_names)
cm_plot <- autoplot(cm, type = "heatmap") +
scale_fill_gradient(low="#D6EAF8",high = "#2E86C1") +
# scale_fill_gradient(low="lightblue", high = "blue") +
theme(legend.position = "right", text = element_text(size=20, color="black",)) +
ggtitle("LOOCV NBC")
cm_plot
fisher.test(table(true_class_names, predicted_class_names))
ggsave(plot = cm_plot, filename = paste0(outdirectory, "NBC_LOOCV_classification_confusion_matrix.pdf"), device = "pdf", height = 3, width = 4)
# Classification Rates
sum(pred) == successes # must be true
# Asthma Success Rate:
print("Asthma Success Rate:")
sum(cbind(data.frame(unlist(pred)), my_sample_data[,2])[,1][cbind(data.frame(unlist(pred)), my_sample_data[,2])[,2]=="asthmatic"])/sum(my_sample_data[,2] == "asthmatic")
# Healthy Success Rate:
print("Healthy Success Rate:")
sum(cbind(data.frame(unlist(pred)), my_sample_data[,2])[,1][cbind(data.frame(unlist(pred)), my_sample_data[,2])[,2]=="healthy"])/sum(my_sample_data[,2] == "healthy")
# LOOCV classification rate:
print("LOOCV Classification Rate")
print(sum(pred)/length(pred))
# Get sample scores to compare to non-CV full model
scores_by_sample_LOOCV_df <- data.frame(as.matrix(unlist(scores)))
rownames(scores_by_sample_LOOCV_df) <- sample_names_ordered
names(scores_by_sample_LOOCV_df) <- "scores_by_sample"
scores_by_sample_LOOCV_df$asthma <- my_sample_data[,2][my_sample_data[,1]==row.names(scores_by_sample_LOOCV_df)]
scores_by_sample_LOOCV_df$asthma <- factor(scores_by_sample_LOOCV_df$asthma)
scores_by_sample_plot <-
ggplot(data = scores_by_sample_LOOCV_df,
mapping = aes(x = seq(1, dim(scores_by_sample_LOOCV_df)[1]),
y = scores_by_sample_LOOCV_df$scores_by_sample[order(scores_by_sample_LOOCV_df$scores_by_sample)],
color = asthma))+
geom_point()+
labs(title="Score (diff of log probs) \n for each sample",
x="Ranked Sample", y = "log(Pr(A|x))-log(Pr(H|x))")+
theme_classic()
scores_by_sample_plot
# ----------- UNCOMMENT TO SAVE ------------
saveRDS(scores_by_sample_LOOCV_df, file = paste0("~/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/NBC_evaluation/", ASVTABLE, "_MAP_md", my_minimum_detection, "_RAmd", my_min_rel_abund, "/LOOCV_scores_by_sample_df.rds"))
# saveRDS(scores_by_sample_LOOCV_df, file = paste0("~/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/NBC_evaluation/", ASVTABLE, "_MAP_md", my_minimum_detection, "_RAmd", my_min_rel_abund, "/RAREFIED_LOOCV_scores_by_sample_df.rds"))
# scores_by_sample_LOOCV_df=readRDS(file = paste0("~/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/NBC_evaluation/", ASVTABLE, "_MAP_md", my_minimum_detection, "_RAmd", my_min_rel_abund, "/LOOCV_scores_by_sample_df.rds"))
# Platt-Scaling
true_class_binary = ifelse(scores_by_sample_LOOCV_df$asthma == "asthmatic", 1, 0)
scores_by_sample_LOOCV_df$true_class_binary = true_class_binary
dat_for_sigmoid<-data.frame(scores_by_sample_LOOCV_df$scores_by_sample, true_class_binary)
colnames(dat_for_sigmoid)<-c("x","y")
plot(dat_for_sigmoid, main="LOOCV score by sample")
modelCV_log<-glm(dat_for_sigmoid$y~dat_for_sigmoid$x, family = binomial, maxit=100)
scores_by_sample_LOOCV_df$scores_by_sample_platt<-predict(modelCV_log, dat_for_sigmoid[-2], type = "response")
plot(scores_by_sample_LOOCV_df$scores_by_sample_platt,
scores_by_sample_LOOCV_df$true_class_binary, main="LOOCV Platt-Scaled Scores by Sample",
xlab = "Platt-scaled scores",
ylab = "True Class")
hist(scores_by_sample_LOOCV_df[scores_by_sample_LOOCV_df$true_class_binary==1,]$scores_by_sample_platt,
main = "Asthmatic", xlab = "Platt-scaled LOOCV score by sample")
hist(scores_by_sample_LOOCV_df[scores_by_sample_LOOCV_df$true_class_binary==0,]$scores_by_sample_platt,
main = "Healthy", xlab = "LOOCV Platt-scaled score by sample")
# get median number of ASVs used:
featurestot <- c()
for (i in 1:num_samples) {
# featurestot[1,i] <- length(savedTests[[i]]$score_per_feature_per_sample)
featurestot <- c(featurestot, length(savedTests[[i]]$score_per_feature_per_sample))
}
median(featurestot) # 462 for min detection of 2
#####
# Confusion Matrix
library(yardstick)
library(ggplot2)
predicted_class_names = pred_class
true_class_names = ifelse(scores_by_sample_LOOCV_df$asthma == "asthmatic", "asthmatic", "healthy")
truth_predicted <- data.frame(true_class_binary, predicted_class_names, true_class_names)
truth_predicted$true_class_binary <- as.factor(truth_predicted$true_class_binary)
# truth_predicted$predicted_class <- as.factor(truth_predicted$predicted_class)
truth_predicted$predicted_class_names <- as.factor(truth_predicted$predicted_class_names)
truth_predicted$true_class_names <- as.factor(truth_predicted$true_class_names)
cm <- conf_mat(truth_predicted, true_class_names, predicted_class_names)
cm_plot <- autoplot(cm, type = "heatmap") +
scale_fill_gradient(low="#D6EAF8",high = "#2E86C1") +
# scale_fill_gradient(low="lightblue", high = "blue") +
theme(legend.position = "right", text = element_text(size=20, color="black"))
cm_plot
fisher.test(table(true_class_names, predicted_class_names))
compare_nariel_to_paper_nbc_loocv = cbind(pred_out_nariel[, c("samplename", "success", "score")], pred_out[, c("samplename", "success", "score")])
write.csv(compare_nariel_to_paper_nbc_loocv, file = "/Users/naomiwilson/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/nariel_evaluation/ASVONLY_MAP_md7_RAmd0/compare_nariel_to_paper_nbc_loocv.csv")
write.table(compare_nariel_to_paper_nbc_loocv, file = "/Users/naomiwilson/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/nariel_evaluation/ASVONLY_MAP_md7_RAmd0/compare_nariel_to_paper_nbc_loocv.csv")
saveRDS(compare_nariel_to_paper_nbc_loocv, file = "/Users/naomiwilson/Box/Kau Lab/Results/MARS/16S_Analysis_AJH/updated_16S_021320/nariel_evaluation/ASVONLY_MAP_md7_RAmd0/compare_nariel_to_paper_nbc_loocv.rds")
View(compare_nariel_to_paper_nbc_loocv)
compare_nariel_to_paper_nbc_loocv$success
compare_nariel_to_paper_nbc_loocv$success == compare_nariel_to_paper_nbc_loocv$success.2
sum(compare_nariel_to_paper_nbc_loocv$success)
typeof(compare_nariel_to_paper_nbc_loocv$success)
